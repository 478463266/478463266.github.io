---
layout: post
title: 计算复杂度 
categories: 学术
description: 计算复杂度相关概念总结
keywords: 
---

###  时间复杂度 $T(n)$: [维基百科](https://en.wikipedia.org/wiki/Time_complexity) 

​	在进行算法分析时，语句总的执行次数T(n)是关于问题规模n的函数，进而分析T(n)随n的变化情况并确定T(n)的数量级。算法的时间复杂度，也就是算法的时间量度。记作：T(n)=O(f(n))。它表示随问题n的增大，算法执行时间的增长率和f(n)的增长率相同，称作算法的渐进时间复杂度，简称为时间复杂度。其中，f(n)是问题规模n的某个函数。

​	这样用大写O()来体现算法时间复杂度的记法，我们称之为**大0记法**。 

​	常见：常数阶-线性阶-对数阶-平方阶-立方阶

![img](D:\blog\images\T(n)-1.jpg) 

​	常用的时间复杂度所耗费的时间从小到大依次是： 

![img](D:\blog\images\T(n)-2.jpg) 

### 空间复杂度 $S(n)$: 

​	算法的空间复杂度通过计算算法所需的存储空间实现，算法空间复杂度的计算公式记作:S(n)= O(f(n))，其中，n为问题的规模，f(n)为语句关于n所占存储空间的函数。
	一般情况下，一个程序在机器上执行时，除了需要存储程序本身的指令、常数、变量和输入数据外，还需要存储对数据操作的存储单元，若输入数据所占空间只取决于问题本身，和算法无关，这样只需要分析该算法在实现时所需的辅助单元即可。若算法执行时所需的辅助空间相对于输入数据量而言是个常数，则称此算法为原地工作，空间复杂度为0(1)。
	通常， 我们都使用"时间复杂度"来指运行时间的需求，使用"空间复杂度"指空间需求。当不用限定词地使用"复杂度'时，通常都是指时间复杂度。

​	存储空间一般包括三个方面：

* 输入数据所占用的存储空间；指令常数变量所占用的存储空间；辅助（存储）空间。
* 一般地，算法的空间复杂度指的是辅助空间。如：一维数组a[n]：空间复杂度 O(n)二维数组a[n][m]：空间复杂度 O(n*m)



[一些例子](https://blog.csdn.net/jsjwk/article/details/84315770)



### 常用算法$T(n)$以及$S(n)$: [ref](http://bigocheatsheet.com/)

## **Searching**

| **Algorithm**                                                | **Data Structure**                        | **Time Complexity**          | **Space Complexity**         |           |
| ------------------------------------------------------------ | ----------------------------------------- | ---------------------------- | ---------------------------- | --------- |
|                                                              |                                           | **Average**                  | **Worst**                    | **Worst** |
| [Depth First Search (DFS)](http://en.wikipedia.org/wiki/Depth-first_search) | Graph of \|V\| vertices and \|E\| edges   | -                            | O(\|E\| + \|V\|)             | O(\|V\|)  |
| [Breadth First Search (BFS)](http://en.wikipedia.org/wiki/Breadth-first_search) | Graph of \|V\| vertices and \|E\| edges   | -                            | O(\|E\| + \|V\|)             | O(\|V\|)  |
| [Binary search](http://en.wikipedia.org/wiki/Binary_search_algorithm) | Sorted array of n elements                | O(log(n))                    | O(log(n))                    | O(1)      |
| [Linear (Brute Force)](http://en.wikipedia.org/wiki/Brute-force_search) | Array                                     | O(n)                         | O(n)                         | O(1)      |
| [Shortest path by Dijkstra,  using a Min-heap as priority queue](http://en.wikipedia.org/wiki/Dijkstra%27s_algorithm) | Graph with \|V\| vertices and \|E\| edges | O((\|V\| + \|E\|) log \|V\|) | O((\|V\| + \|E\|) log \|V\|) | O(\|V\|)  |
| [Shortest path by Dijkstra,  using an unsorted array as priority queue](http://en.wikipedia.org/wiki/Dijkstra%27s_algorithm) | Graph with \|V\| vertices and \|E\| edges | O(\|V\|^2)                   | O(\|V\|^2)                   | O(\|V\|)  |
| [Shortest path by Bellman-Ford](http://en.wikipedia.org/wiki/Bellman%E2%80%93Ford_algorithm) | Graph with \|V\| vertices and \|E\| edges | O(\|V\|\|E\|)                | O(\|V\|\|E\|)                | O(\|V\|)  |

 

## **Sorting**

| **Algorithm**                                                | **Data Structure** | **Time Complexity** | **Worst Case Auxiliary Space Complexity** |             |           |
| ------------------------------------------------------------ | ------------------ | ------------------- | ----------------------------------------- | ----------- | --------- |
|                                                              |                    | **Best**            | **Average**                               | **Worst**   | **Worst** |
| [Quicksort](http://en.wikipedia.org/wiki/Quicksort)          | Array              | O(n log(n))         | O(n log(n))                               | O(n^2)      | O(n)      |
| [Mergesort](http://en.wikipedia.org/wiki/Merge_sort)         | Array              | O(n log(n))         | O(n log(n))                               | O(n log(n)) | O(n)      |
| [Heapsort](http://en.wikipedia.org/wiki/Heapsort)            | Array              | O(n log(n))         | O(n log(n))                               | O(n log(n)) | O(1)      |
| [Bubble Sort](http://en.wikipedia.org/wiki/Bubble_sort)      | Array              | O(n)                | O(n^2)                                    | O(n^2)      | O(1)      |
| [Insertion Sort](http://en.wikipedia.org/wiki/Insertion_sort) | Array              | O(n)                | O(n^2)                                    | O(n^2)      | O(1)      |
| [Select Sort](http://en.wikipedia.org/wiki/Selection_sort)   | Array              | O(n^2)              | O(n^2)                                    | O(n^2)      | O(1)      |
| [Bucket Sort](http://en.wikipedia.org/wiki/Bucket_sort)      | Array              | O(n+k)              | O(n+k)                                    | O(n^2)      | O(nk)     |
| [Radix Sort](http://en.wikipedia.org/wiki/Radix_sort)        | Array              | O(nk)               | O(nk)                                     | O(nk)       | O(n+k)    |

## **Data Structures**

| **Data Structure**                                           | **Time Complexity** | **Space Complexity** |               |              |              |            |               |              |             |
| ------------------------------------------------------------ | ------------------- | -------------------- | ------------- | ------------ | ------------ | ---------- | ------------- | ------------ | ----------- |
|                                                              | **Average**         | **Worst**            | **Worst**     |              |              |            |               |              |             |
|                                                              | **Indexing**        | **Search**           | **Insertion** | **Deletion** | **Indexing** | **Search** | **Insertion** | **Deletion** |             |
| [Basic Array](http://en.wikipedia.org/wiki/Array_data_structure) | O(1)                | O(n)                 | -             | -            | O(1)         | O(n)       | -             | -            | O(n)        |
| [Dynamic Array](http://en.wikipedia.org/wiki/Dynamic_array)  | O(1)                | O(n)                 | O(n)          | O(n)         | O(1)         | O(n)       | O(n)          | O(n)         | O(n)        |
| [Singly-Linked List](http://en.wikipedia.org/wiki/Singly_linked_list#Singly_linked_lists) | O(n)                | O(n)                 | O(1)          | O(1)         | O(n)         | O(n)       | O(1)          | O(1)         | O(n)        |
| [Doubly-Linked List](http://en.wikipedia.org/wiki/Doubly_linked_list) | O(n)                | O(n)                 | O(1)          | O(1)         | O(n)         | O(n)       | O(1)          | O(1)         | O(n)        |
| [Skip List](http://en.wikipedia.org/wiki/Skip_list)          | O(log(n))           | O(log(n))            | O(log(n))     | O(log(n))    | O(n)         | O(n)       | O(n)          | O(n)         | O(n log(n)) |
| [Hash Table](http://en.wikipedia.org/wiki/Hash_table)        | -                   | O(1)                 | O(1)          | O(1)         | -            | O(n)       | O(n)          | O(n)         | O(n)        |
| [Binary Search Tree](http://en.wikipedia.org/wiki/Binary_search_tree) | O(log(n))           | O(log(n))            | O(log(n))     | O(log(n))    | O(n)         | O(n)       | O(n)          | O(n)         | O(n)        |
| [Cartresian Tree](https://en.wikipedia.org/wiki/Cartesian_tree) | -                   | O(log(n))            | O(log(n))     | O(log(n))    | -            | O(n)       | O(n)          | O(n)         | O(n)        |
| [B-Tree](http://en.wikipedia.org/wiki/B_tree)                | O(log(n))           | O(log(n))            | O(log(n))     | O(log(n))    | O(log(n))    | O(log(n))  | O(log(n))     | O(log(n))    | O(n)        |
| [Red-Black Tree](http://en.wikipedia.org/wiki/Red-black_tree) | O(log(n))           | O(log(n))            | O(log(n))     | O(log(n))    | O(log(n))    | O(log(n))  | O(log(n))     | O(log(n))    | O(n)        |
| [Splay Tree](https://en.wikipedia.org/wiki/Splay_tree)       | -                   | O(log(n))            | O(log(n))     | O(log(n))    | -            | O(log(n))  | O(log(n))     | O(log(n))    | O(n)        |
| [AVL Tree](http://en.wikipedia.org/wiki/AVL_tree)            | O(log(n))           | O(log(n))            | O(log(n))     | O(log(n))    | O(log(n))    | O(log(n))  | O(log(n))     | O(log(n))    | O(n)        |

## **Heaps**

| **Heaps**                                                    | **Time Complexity** |              |                 |                  |            |            |           |      |
| ------------------------------------------------------------ | ------------------- | ------------ | --------------- | ---------------- | ---------- | ---------- | --------- | ---- |
|                                                              | **Heapify**         | **Find Max** | **Extract Max** | **Increase Key** | **Insert** | **Delete** | **Merge** |      |
| [Linked List (sorted)](http://en.wikipedia.org/wiki/Linked_list) | -                   | O(1)         | O(1)            | O(n)             | O(n)       | O(1)       | O(m+n)    |      |
| [Linked List (unsorted)](http://en.wikipedia.org/wiki/Linked_list) | -                   | O(n)         | O(n)            | O(1)             | O(1)       | O(1)       | O(1)      |      |
| [Binary Heap](http://en.wikipedia.org/wiki/Binary_heap)      | O(n)                | O(1)         | O(log(n))       | O(log(n))        | O(log(n))  | O(log(n))  | O(m+n)    |      |
| [Binomial Heap](http://en.wikipedia.org/wiki/Binomial_heap)  | -                   | O(log(n))    | O(log(n))       | O(log(n))        | O(log(n))  | O(log(n))  | O(log(n)) |      |
| [Fibonacci Heap](http://en.wikipedia.org/wiki/Fibonacci_heap) | -                   | O(1)         | O(log(n))*      | O(1)*            | O(1)       | O(log(n))* | O(1)      |      |

## **Graphs**

| **Node / Edge Management**                                   | **Storage**      | **Add Vertex**   | **Add Edge**     | **Remove Vertex** | **Remove Edge**  | **Query** |
| ------------------------------------------------------------ | ---------------- | ---------------- | ---------------- | ----------------- | ---------------- | --------- |
| [Adjacency list](http://en.wikipedia.org/wiki/Adjacency_list) | O(\|V\|+\|E\|)   | O(1)             | O(1)             | O(\|V\| + \|E\|)  | O(\|E\|)         | O(\|V\|)  |
| [Incidence list](http://en.wikipedia.org/wiki/Incidence_list) | O(\|V\|+\|E\|)   | O(1)             | O(1)             | O(\|E\|)          | O(\|E\|)         | O(\|E\|)  |
| [Adjacency matrix](http://en.wikipedia.org/wiki/Adjacency_matrix) | O(\|V\|^2)       | O(\|V\|^2)       | O(1)             | O(\|V\|^2)        | O(1)             | O(1)      |
| [Incidence matrix](http://en.wikipedia.org/wiki/Incidence_matrix) | O(\|V\| ⋅ \|E\|) | O(\|V\| ⋅ \|E\|) | O(\|V\| ⋅ \|E\|) | O(\|V\| ⋅ \|E\|)  | O(\|V\| ⋅ \|E\|) | O(\|E\|)  |

## **Notation forasymptotic growth**

| **letter**      | **bound**                                                    | **growth**                                                   |
| --------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| (theta) Θ       | upper and lower, tight[[1\]](http://bigocheatsheet.com/#footnote-1) | equal[[2\]](http://bigocheatsheet.com/#footnote-1)           |
| (big-oh) O      | upper, tightness unknown                                     | less than or equal[[3\]](http://bigocheatsheet.com/#footnote-1) |
| (small-oh) o    | upper, not tight                                             | less than                                                    |
| (big omega) Ω   | lower, tightness unknown                                     | greater than or equal                                        |
| (small omega) ω | lower, not tight                                             | greater than                                                 |

[1] Big O is theupper bound, while Omega is the lower bound. Theta requires both Big O andOmega, so that's why it's referred to as a tight bound (it must be both theupper and lower bound). For example, an algorithm taking Omega(n log n) takesat least n log n time but has no upper limit. An algorithm taking Theta(n logn) is far preferential since it takes AT LEAST n log n (Omega n log n) and NOMORE THAN n log n (Big O n log n).[SO](http://stackoverflow.com/a/464081/412916)

[2] f(x)=Θ(g(n))means f (the running time of the algorithm) grows exactly like g when n (inputsize) gets larger. In other words, the growth rate of f(x) is asymptoticallyproportional to g(n).

[3] Same thing.Here the growth rate is no faster than g(n). big-oh is the most useful becauserepresents the worst-case behavior.

In short, if algorithm is __ then its performance is __

| **algorithm** | **performance** |
| ------------- | --------------- |
| o(n)          | < n             |
| O(n)          | ≤ n             |
| Θ(n)          | = n             |
| Ω(n)          | ≥ n             |
| ω(n)          | > n             |

 



