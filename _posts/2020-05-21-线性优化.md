---
layout: post
title: 线性优化
categories: [学术]
description: 常见线性优化方法
keywords: 线性优化
---

相关概念：

[详细解释](https://blog.csdn.net/frostime/article/details/90291392)

* **线性规划(LP)** ： 目标函数和约束条件皆为线性的最优化问题，能够应用于网络流，多商品流量等问题。很多最优化问题一般都要分解为线性规划子问题，然后逐一求解。形式化描述如下所示：

* ![线性规划](../images/LP.jpg)

  [详细介绍](https://zh.wikipedia.org/wiki/%E7%BA%BF%E6%80%A7%E8%A7%84%E5%88%92)；一般求解方法：单纯形法(当线性方程组的变量数大于方程个数,基本思想：每一次比上一次更优，[详细介绍](https://www.hrwhisper.me/introduction-to-simplex-algorithm/))+大M法（线性规划问题的约束条件等式或大于型时，使用人工变量法后，寻找其初始基可行解的一种方法；即将有 if-then 结构的非线性约束线性化，会引入0-1变量）；两阶段法。

  <img src="/Users/rw/Documents/blog/478463266.github.io/images/大M法.png" alt="大M法" style="zoom:80%;" />

* 非线性规划：目标函数和约束条件存在非线性（比如，二次）的最优化问题。场景：连续位置优化、成本非平滑变化（比如无源电路、石油产品运算）。一般求解求解方法：[维基]([https://zh.wikipedia.org/wiki/%E9%9D%9E%E7%BA%BF%E6%80%A7%E8%A7%84%E5%88%92](https://zh.wikipedia.org/wiki/非线性规划)); 常用解决方法：非线性最小二乘、一阶梯度和二阶梯度法、高斯牛顿法、LM算法。解决框架分为Line Search 和Trust Region两类-Line Search 先固定搜索方向，然后在该方向上寻找步长，以最速下降法和高斯牛顿法为代表。而Trust Region是先固定搜索区域，再考虑该区域里面的最优点，此类方法以LM算法为代表

* 整数规划Integer (linear) programming(ILP)，是一种数学优化模型，其中目标函数和约束条件的变量都是整数的线性优化问题，是NP-hard问题。可用于电信、蜂窝网络的网络优化，详细解释和常见解决方法见[维基百科](https://en.wikipedia.org/wiki/Integer_programming)，论文见[Bandwidth Calendaring: Dynamic Services Scheduling over Software Defined Networks](http://ieeexplore.ieee.org/abstract/document/7510888/)。

* 凸优化

* 平衡

* primal and dual原始对偶问题：用于问题优化，对偶问题为原问题提供了一个下界，primal和dual问题本来是会存在一个dual gap。如果有个比较强的约束条件（KTT）（when the problem is convex and satisfies ），那么dual gap=0.这叫做强对偶，那么就可以根据dual问题直接求得primal问题的解。而一般dual gap=primal-dual>0，称为弱对偶性。线性情况下，如果原问题有n个变量，m个限制条件，那么对偶问题就有m个对偶变量，n个限制条件。即使初始问题是non-convex，但是拉格朗日dual problem是convex的。拉格朗日的乘子就是拉格朗日对偶变量。

* 拉格朗日松弛：用在优化问题里面（假设是最小化问题），而且一定是有约束条件的优化问题，是一种求解约束规划的数学方法。简单来说就是发constraints弄到objective上面，加很大的penalty，大到满足这个constraint，就和原问题等价了，这样就变成没有约束条件的问题求解了。详细介绍见[维基百科](https://en.wikipedia.org/wiki/Lagrangian_relaxation)和[知乎](https://www.zhihu.com/question/21345731/answer/57182129)。把有约束优化问题转化成无约束优化问题。具体方法是**Augmented Lagrange Method增广拉格朗日乘子法** ，用来解决等式约束下的优化问题。另外还有**二次惩罚方法**， 详见[网址](http://blog.csdn.net/fangqingan_java/article/details/50001843).

* **拉格朗日乘子法**：是一种寻找有等式约束条件的函数的最优值(最大或者最小)的最优化方法，[详细介绍](https://blog.csdn.net/sinat_17496535/article/details/52103852)。

* **KKT条件**：是拉格朗日乘子法的拓展,是一种求取含不等式约束条件的函数最优值的方法. 

* **拉格朗日对偶**：将原始问题转化为对偶问题。通过解对偶问题而得到原始问题的解，[详细解释](https://www.cnblogs.com/90zeng/p/Lagrange_duality.html)；[详细解释2](https://blog.csdn.net/frostime/article/details/90291392)

* 比如说，![](/Users/rw/Documents/blog/478463266.github.io/images/Lagrangean dual problem.png)


  * **广义拉格朗日函数**：其中$\alpha_i$和$\beta_i$就是上面提到的拉格朗日乘子（参数）。![](/Users/rw/Documents/blog/478463266.github.io/images/广义拉格朗日函数.jpg)
  * **增广拉格朗日乘子法**：用来解决等式约束下的优化问题，解释见[网址](https://www.cnblogs.com/lochan/p/6000678.html)。

* Linear programming relaxation(松弛问题)： the relaxation of a (mixed) integer linear program is the problem that arises by removing the integrality constraint of each variable.[中文解释]([https://baike.baidu.com/item/%E6%9D%BE%E5%BC%9B%E9%97%AE%E9%A2%98/22110248?fr=aladdin](https://baike.baidu.com/item/松弛问题/22110248?fr=aladdin))

解决方法：

* Mirror descend
* 次梯度
* 多目标：MOEA/D
* proximal algorithm：一种比传统的gradient descent方法更general（适用于任何合理的"非欧式（non Euclidean）"距离）
* ADMM(交替方向乘子法): 常见的约束问题最优化通用框架，适用于求解分布式凸优化问题，特别是统计学习问题。其通过分解协调（Decomposition-Coordination）过程，将大的全局问题分解为多个较小、较容易求解的局部子问题，并通过协调子问题的解而得到大的全局问题的解。关注点是**凸优化**和**分布式**。