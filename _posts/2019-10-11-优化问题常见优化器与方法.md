---
layout: post
title: 优化器
categories: 学术
description: 优化器
keywords: 
---

常见优化器：

- CPLEX +  Yalmip 


* GNU Linear Programming Kit (GLPK) 
* Gurobi
* LINGO
* MATLAB本身的优化器
* Mathematica

常用优化方法：

* ADMM(交替方向乘子法): 常见的约束问题最优化通用框架，适用于求解分布式凸优化问题，特别是统计学习问题。其通过分解协调（Decomposition-Coordination）过程，将大的全局问题分解为多个较小、较容易求解的局部子问题，并通过协调子问题的解而得到大的全局问题的解。关注点是**凸优化**和**分布式**。
* primal and dual原始对偶问题：用于问题优化，对偶问题为原问题提供了一个下界，primal和dual问题本来是会存在一个dual gap。如果有个比较强的约束条件（KTT）（when the problem is convex and satisfies ），那么dual gap=0.这叫做强对偶，那么就可以根据dual问题直接求得primal问题的解。而一般dual gap=primal-dual>0，称为弱对偶性。线性情况下，如果原问题有n个变量，m个限制条件，那么对偶问题就有m个对偶变量，n个限制条件。即使初始问题是non-convex，但是拉格朗日dual problem是convex的。拉格朗日的乘子就是拉格朗日对偶变量。详细见[维基百科](https://en.wikipedia.org/wiki/Duality_(optimization)) 。
* 对偶问题：某些条件下，把原始的约束问题通过拉格朗日函数转化为无约束问题，如果原始问题求解棘手，在满足KKT的条件下用求解对偶问题来代替求解原始问题，使得问题求解更加容易，[具体介绍](https://blog.csdn.net/fkyyly/article/details/86488582) ，[具体介绍2](https://blog.csdn.net/bbbeoy/article/details/72461586)。
* 次梯度法：subgradient中文名叫次梯度，和梯度一样，完全可以多放梯度使用，至于为什么叫子梯度，是因为有一些凸函数是不可导的，没法用梯度，所以subgradient就在这里使用了。注意到，子梯度也是求解凸函数的，只是凸函数不是处处可导，[具体使用方法](https://blog.csdn.net/lansatiankongxxc/article/details/46386341)
* 两阶段法: 寻找线性规划问题初始基可行解的一种方法，把增加人工变量的线性规划问题分为两个阶段去求解。第一阶段主要是为了得到原问题的一个基本可行解，第二阶段是在第一阶段得到的基本可行解的基础上求解原线性规划问题
  * 大M法与两阶段法都是在原问题缺少初始可行基的情况下利用引人人工变量构造人工基，以达到运用单纯形法求解原问题的目的。用[大M法](https://baike.baidu.com/item/大M法)处理人工变量，手工计算求解时不会碰到麻烦。但用电子计算机求解时，对M就只能在计算机内输出一个机器最大字长的数字。如果线性规划问题中的aij、bi或cj等参数值与这个代表M的数比较接近，或远远小于这个数字，由计算机计算时有可能使计算结果发生错误，从而使求解的最终结果与原问题真正的最优解不一致。为了克服这个困难，可以对添加人工变量后的线性规划问题分为两个阶段来计算，而避免M的使用，这个方法称为两阶段法
* 大M法

* Benders Decomposition